{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cosinuss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBEvUb+6GsxhOQQgFzTyCY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supertime1/Floyer_Analysis/blob/main/Cosinuss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUCjV4YaSzpT"
      },
      "source": [
        "#1. Set up dependency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_NhMO3JRJC0"
      },
      "source": [
        "import sys\r\n",
        "sys.path.append('C:/Users/57lzhang.US04WW4008/PycharmProjects/cosinuss')"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buQcxbm5RvZd"
      },
      "source": [
        "from data_container import config, DataFile\r\n",
        "from data_container.api_db_sync import DBSync\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import datetime\r\n",
        "import pickle"
      ],
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae-3xQw-S4E9"
      },
      "source": [
        "#2.Connect to Cosinuss Database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlPl6rEfprbe"
      },
      "source": [
        "Open redis-server.exe first before running configure_api() "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU7_4mYhR1ou",
        "outputId": "b1bb3b96-0777-4260-8cab-61e1f03d0d1e"
      },
      "source": [
        "def configure_api(db_name, username, update_local=False):\r\n",
        "    \"\"\"\r\n",
        "    Configure api as the data handler\r\n",
        "    \"\"\"\r\n",
        "    try:\r\n",
        "        config.init(db_name=db_name)\r\n",
        "        api = DBSync(username=username,\r\n",
        "                    server = 'https://telecovid.earconnect.de')\r\n",
        "    except:\r\n",
        "        print('Configure API failed')\r\n",
        "        return\r\n",
        "    # password: teeshau7aiMonoh9ee\r\n",
        "    if update_local:\r\n",
        "    # download data from the server\r\n",
        "        api.pull_all_dfs(prj_hash_id='M9KH')\r\n",
        "    \r\n",
        "    df_list_local = api.df_list(prj_hash_id='M9KH')\r\n",
        "    print('There are', len(df_list_local), 'files in local database')\r\n",
        "    return api\r\n",
        "\r\n",
        "\r\n",
        "api = configure_api('sonova_analysis', 'sonova.fremont.api')"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-05 09:34:51 - ERROR -       dc_config:  52 - data_container.config.init() can only be called once\n",
            "2021-03-05 09:34:55 -  INFO -       api_login: 241 - login: sonova.fremont.api @ https://telecovid.earconnect.de\n",
            "2021-03-05 09:34:56 -  INFO -       api_login: 253 - successful login, it expires 2021-03-05 21:34:56 expiring in 720.0 min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "There are 163 files in local database\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "4dKZ65Q_z5b-",
        "outputId": "9c62940b-f542-41c7-bd95-a8634e6900eb"
      },
      "source": [
        "def generate_table(date):\r\n",
        "    \"\"\"\r\n",
        "    Convert local database into a Pandas dataframe, for ease of data analysis\r\n",
        "\r\n",
        "    params:\r\n",
        "    date: select the date that data is generated\r\n",
        "\r\n",
        "    outputs:\r\n",
        "    an overview table in the form of pandas dataframe\r\n",
        "    \"\"\"\r\n",
        "    table = api.overview_dfs()\r\n",
        "    overview_df = pd.DataFrame(table[1:], columns=table[0])\r\n",
        "    # change to lower case for the device name\r\n",
        "    overview_df['device'] = overview_df['device'].str.lower()\r\n",
        "    overview_df.loc[overview_df.device.str.match(r'^polar'), 'device']= 'polar'\r\n",
        "    overview_df = overview_df[overview_df.when > date]\r\n",
        "    overview_df['when'] = [datetime.datetime.strptime(i, '%Y-%m-%d %H:%M:%S') for \r\n",
        "                           i in list(overview_df['when'])]\r\n",
        "    overview_df['duration'] = [datetime.datetime.strptime(i, '%H:%M:%S') for \r\n",
        "                               i in list(overview_df['duration'])]\r\n",
        "    overview_df['end'] = [(overview_df.when.loc[i] \r\n",
        "                           - datetime.datetime(1900, 1, 1) \r\n",
        "                           + overview_df.duration.loc[i]) for i in overview_df.index]\r\n",
        "    return overview_df\r\n",
        "\r\n",
        "table = generate_table('2020-12-31')\r\n",
        "print('There are', len(table), 'test records')\r\n",
        "table.head()"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 63 test records\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               person                when  device              df id  \\\n",
              "100  M9KH.BZYG (RaHe) 2021-02-08 14:15:09   polar  1C2RATHBVH.C4CDEZ   \n",
              "101  M9KH.BZYG (RaHe) 2021-02-08 14:15:14  cshell  1C2RATHBVH.38CD8K   \n",
              "102  M9KH.BZYG (RaHe) 2021-02-08 14:15:23  cshell  1C2RATHBVH.LEMWKL   \n",
              "103  M9KH.BZYG (RaHe) 2021-02-08 14:15:35  garmin  8QEK89R9B4.NZH5XL   \n",
              "104  M9KH.ME9A (LeLo) 2021-02-08 15:23:00   polar  1C2RATHBVH.XCMFW1   \n",
              "\n",
              "               duration samples                                 cols  \\\n",
              "100 1900-01-01 00:34:48   2.1 K                           heart_rate   \n",
              "101 1900-01-01 00:34:42   1.7 M  ppg_ir, ppg_ir_2, ppg_ir_3, ppg_...   \n",
              "102 1900-01-01 00:34:36   1.7 M  ppg_ir, ppg_ir_2, ppg_ir_3, ppg_...   \n",
              "103 1900-01-01 00:45:27   2.7 K                           heart_rate   \n",
              "104 1900-01-01 00:34:34   2.1 K                           heart_rate   \n",
              "\n",
              "                    end  \n",
              "100 2021-02-08 14:49:57  \n",
              "101 2021-02-08 14:49:56  \n",
              "102 2021-02-08 14:49:59  \n",
              "103 2021-02-08 15:01:02  \n",
              "104 2021-02-08 15:57:34  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person</th>\n",
              "      <th>when</th>\n",
              "      <th>device</th>\n",
              "      <th>df id</th>\n",
              "      <th>duration</th>\n",
              "      <th>samples</th>\n",
              "      <th>cols</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>M9KH.BZYG (RaHe)</td>\n",
              "      <td>2021-02-08 14:15:09</td>\n",
              "      <td>polar</td>\n",
              "      <td>1C2RATHBVH.C4CDEZ</td>\n",
              "      <td>1900-01-01 00:34:48</td>\n",
              "      <td>2.1 K</td>\n",
              "      <td>heart_rate</td>\n",
              "      <td>2021-02-08 14:49:57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>M9KH.BZYG (RaHe)</td>\n",
              "      <td>2021-02-08 14:15:14</td>\n",
              "      <td>cshell</td>\n",
              "      <td>1C2RATHBVH.38CD8K</td>\n",
              "      <td>1900-01-01 00:34:42</td>\n",
              "      <td>1.7 M</td>\n",
              "      <td>ppg_ir, ppg_ir_2, ppg_ir_3, ppg_...</td>\n",
              "      <td>2021-02-08 14:49:56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>M9KH.BZYG (RaHe)</td>\n",
              "      <td>2021-02-08 14:15:23</td>\n",
              "      <td>cshell</td>\n",
              "      <td>1C2RATHBVH.LEMWKL</td>\n",
              "      <td>1900-01-01 00:34:36</td>\n",
              "      <td>1.7 M</td>\n",
              "      <td>ppg_ir, ppg_ir_2, ppg_ir_3, ppg_...</td>\n",
              "      <td>2021-02-08 14:49:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>M9KH.BZYG (RaHe)</td>\n",
              "      <td>2021-02-08 14:15:35</td>\n",
              "      <td>garmin</td>\n",
              "      <td>8QEK89R9B4.NZH5XL</td>\n",
              "      <td>1900-01-01 00:45:27</td>\n",
              "      <td>2.7 K</td>\n",
              "      <td>heart_rate</td>\n",
              "      <td>2021-02-08 15:01:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>M9KH.ME9A (LeLo)</td>\n",
              "      <td>2021-02-08 15:23:00</td>\n",
              "      <td>polar</td>\n",
              "      <td>1C2RATHBVH.XCMFW1</td>\n",
              "      <td>1900-01-01 00:34:34</td>\n",
              "      <td>2.1 K</td>\n",
              "      <td>heart_rate</td>\n",
              "      <td>2021-02-08 15:57:34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bovy12uwygfx"
      },
      "source": [
        " def correct_label(table):\r\n",
        "    \"\"\"\r\n",
        "    fix the labeling problem of cshell and biometric\r\n",
        "    \r\n",
        "    params:\r\n",
        "    overview table from generate_table function\r\n",
        "\r\n",
        "    outputs:\r\n",
        "    updated table with correct cshell and biometric labels\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    def get_device_model(df):\r\n",
        "        \"\"\"\r\n",
        "        get device\r\n",
        "        \r\n",
        "        params:\r\n",
        "        df - output of api.pull_df\r\n",
        "        \r\n",
        "        outputs:\r\n",
        "        correct device label for df\r\n",
        "        \"\"\"\r\n",
        "        # get device\r\n",
        "        if df.device:\r\n",
        "            device_model = df.device.device_model\r\n",
        "        else:\r\n",
        "            device_model = df.device_model\r\n",
        "        \r\n",
        "        if 'polar' in device_model.lower():\r\n",
        "            return 'polar'\r\n",
        "\r\n",
        "        elif 'biomeric' in device_model.lower() or 'cshell' in device_model.lower():\r\n",
        "            if 'ppg_ir_2' in list(df.cols):\r\n",
        "                some_data = df.c.ppg_ir_2.y[600:650]\r\n",
        "                if list(some_data):\r\n",
        "                    ppg_mean = np.mean(some_data)\r\n",
        "                else:\r\n",
        "                    return 'na'\r\n",
        "            else:\r\n",
        "                ppg_mean = 1000\r\n",
        "            \r\n",
        "            if ppg_mean < 500:\r\n",
        "                return 'cshell'\r\n",
        "            else:\r\n",
        "                return 'biometric'\r\n",
        "    \r\n",
        "    def get_correct_label(hash_ids, target_device):\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        \"\"\"\r\n",
        "        # output list of corrected labels\r\n",
        "        corrected_name = []\r\n",
        "        # a counter to record how many labels have been corrected after processing\r\n",
        "        cnt = 0\r\n",
        "        print(f'There are in total {len(hash_ids)} files with {target_device} label')\r\n",
        "        for i in range(len(hash_ids)):\r\n",
        "            try:\r\n",
        "                print(f'api reading {i}th file...')\r\n",
        "                df = api.pull_df(list(hash_ids)[i]) \r\n",
        "            # in case reading file failed\r\n",
        "            except:\r\n",
        "                print(f'api read {i}th file failed!')\r\n",
        "                corrected_name.append(table.loc[hash_ids.index[i]].device)\r\n",
        "                continue\r\n",
        "            # get the new label by api reading the file\r\n",
        "            new_label = get_device_model(df)\r\n",
        "            corrected_name.append(new_label)\r\n",
        "            if new_label != table.loc[hash_ids.index[i]].device:\r\n",
        "                print(f'Person {table.loc[hash_ids.index[i]].person} and \\\r\n",
        "            {target_device} label has been corrected to {new_label}')\r\n",
        "                cnt += 1\r\n",
        "        print(f'There are in total {cnt} files been corrected')\r\n",
        "        return corrected_name\r\n",
        "\r\n",
        "    # get the hash ids of cshell and biometric in original table\r\n",
        "    cshell_hash_ids = table[table.device == 'cshell']['df id']\r\n",
        "    biometric_hash_ids = table[table.device == 'biometric']['df id']\r\n",
        "\r\n",
        "    # get the row index of cshell and biometric in original table\r\n",
        "    original_cshell_index = table[table.device == 'cshell'].index\r\n",
        "    original_biometric_index = table[table.device == 'biometric'].index\r\n",
        "    \r\n",
        "    # update the original table with corrected labels of cshell and biometric\r\n",
        "    table.device.loc[original_cshell_index] = get_correct_label(cshell_hash_ids, \r\n",
        "                                                     'cshell')\r\n",
        "    table.device.loc[original_biometric_index] = get_correct_label(biometric_hash_ids, \r\n",
        "                                                        'biometric')\r\n",
        "\r\n",
        "    return table\r\n",
        "\r\n",
        "table = correct_label(table)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu-ikiG5dpaF"
      },
      "source": [
        "table.to_pickle(\"C:/Users/57lzhang.US04WW4008/PycharmProjects/cosinuss/local_db.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "hxsxno--dmby",
        "outputId": "67f55fb2-c3f7-4662-bf2a-1428da7e68d2"
      },
      "source": [
        "#load table from local directory\r\n",
        "table = pd.read_pickle(\"C:/Users/57lzhang.US04WW4008/PycharmProjects/cosinuss/local_db.pkl\")\r\n",
        "table.head()"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               person                when     device              df id  \\\n",
              "100  M9KH.BZYG (RaHe) 2021-02-08 14:15:09      polar  1C2RATHBVH.C4CDEZ   \n",
              "101  M9KH.BZYG (RaHe) 2021-02-08 14:15:14     cshell  1C2RATHBVH.38CD8K   \n",
              "102  M9KH.BZYG (RaHe) 2021-02-08 14:15:23  biometric  1C2RATHBVH.LEMWKL   \n",
              "103  M9KH.BZYG (RaHe) 2021-02-08 14:15:35     garmin  8QEK89R9B4.NZH5XL   \n",
              "104  M9KH.ME9A (LeLo) 2021-02-08 15:23:00      polar  1C2RATHBVH.XCMFW1   \n",
              "\n",
              "               duration samples                                 cols  \\\n",
              "100 1900-01-01 00:34:48   2.1 K                           heart_rate   \n",
              "101 1900-01-01 00:34:42   1.7 M  ppg_ir, ppg_ir_2, ppg_ir_3, ppg_...   \n",
              "102 1900-01-01 00:34:36   1.7 M  ppg_ir, ppg_ir_2, ppg_ir_3, ppg_...   \n",
              "103 1900-01-01 00:45:27   2.7 K                           heart_rate   \n",
              "104 1900-01-01 00:34:34   2.1 K                           heart_rate   \n",
              "\n",
              "                    end  \n",
              "100 2021-02-08 14:49:57  \n",
              "101 2021-02-08 14:49:56  \n",
              "102 2021-02-08 14:49:59  \n",
              "103 2021-02-08 15:01:02  \n",
              "104 2021-02-08 15:57:34  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person</th>\n",
              "      <th>when</th>\n",
              "      <th>device</th>\n",
              "      <th>df id</th>\n",
              "      <th>duration</th>\n",
              "      <th>samples</th>\n",
              "      <th>cols</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>M9KH.BZYG (RaHe)</td>\n",
              "      <td>2021-02-08 14:15:09</td>\n",
              "      <td>polar</td>\n",
              "      <td>1C2RATHBVH.C4CDEZ</td>\n",
              "      <td>1900-01-01 00:34:48</td>\n",
              "      <td>2.1 K</td>\n",
              "      <td>heart_rate</td>\n",
              "      <td>2021-02-08 14:49:57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>M9KH.BZYG (RaHe)</td>\n",
              "      <td>2021-02-08 14:15:14</td>\n",
              "      <td>cshell</td>\n",
              "      <td>1C2RATHBVH.38CD8K</td>\n",
              "      <td>1900-01-01 00:34:42</td>\n",
              "      <td>1.7 M</td>\n",
              "      <td>ppg_ir, ppg_ir_2, ppg_ir_3, ppg_...</td>\n",
              "      <td>2021-02-08 14:49:56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>M9KH.BZYG (RaHe)</td>\n",
              "      <td>2021-02-08 14:15:23</td>\n",
              "      <td>biometric</td>\n",
              "      <td>1C2RATHBVH.LEMWKL</td>\n",
              "      <td>1900-01-01 00:34:36</td>\n",
              "      <td>1.7 M</td>\n",
              "      <td>ppg_ir, ppg_ir_2, ppg_ir_3, ppg_...</td>\n",
              "      <td>2021-02-08 14:49:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>M9KH.BZYG (RaHe)</td>\n",
              "      <td>2021-02-08 14:15:35</td>\n",
              "      <td>garmin</td>\n",
              "      <td>8QEK89R9B4.NZH5XL</td>\n",
              "      <td>1900-01-01 00:45:27</td>\n",
              "      <td>2.7 K</td>\n",
              "      <td>heart_rate</td>\n",
              "      <td>2021-02-08 15:01:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>M9KH.ME9A (LeLo)</td>\n",
              "      <td>2021-02-08 15:23:00</td>\n",
              "      <td>polar</td>\n",
              "      <td>1C2RATHBVH.XCMFW1</td>\n",
              "      <td>1900-01-01 00:34:34</td>\n",
              "      <td>2.1 K</td>\n",
              "      <td>heart_rate</td>\n",
              "      <td>2021-02-08 15:57:34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nSKkqBi1THp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21368a18-3d90-4c09-c186-c4ea476c76ef"
      },
      "source": [
        "def find_pairs_row_index(table, floyer_device='cshell'):\r\n",
        "    \"\"\"\r\n",
        "    Filter table with paired polar and floyer devices\r\n",
        "    \"\"\"\r\n",
        "    paired_table = table[table.device.isin(['polar', floyer_device])]\r\n",
        "    \r\n",
        "    paired_idx_lst = []\r\n",
        "    # find paried sample ids\r\n",
        "    for person in list(paired_table['person'].unique()):\r\n",
        "        person_paired_table = paired_table[paired_table.person == person]\r\n",
        "        polar_idx_lst = person_paired_table[person_paired_table.device == 'polar'].index\r\n",
        "        floyer_idx_lst = person_paired_table[person_paired_table.device == floyer_device].index\r\n",
        "\r\n",
        "        # find pairs by checking the overlapping time (2*O(n^2))\r\n",
        "        for polar_idx in polar_idx_lst:\r\n",
        "            polar_start_time = person_paired_table.when.loc[polar_idx]\r\n",
        "            polar_end_time = person_paired_table.end.loc[polar_idx]\r\n",
        "\r\n",
        "            for floyer_idx in floyer_idx_lst:\r\n",
        "                floyer_start_time = person_paired_table.when.loc[floyer_idx]\r\n",
        "                floyer_end_time = person_paired_table.end.loc[floyer_idx]\r\n",
        "                \r\n",
        "                if floyer_start_time >= polar_end_time or polar_start_time >= floyer_end_time:\r\n",
        "                    continue\r\n",
        "                else:\r\n",
        "                    paired_idx_lst.append([polar_idx, floyer_idx])\r\n",
        "    \r\n",
        "    return paired_idx_lst\r\n",
        "\r\n",
        "paired_idx_lst = find_pairs_row_index(table, floyer_device='cshell')\r\n",
        "paired_idx_lst"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[100, 101],\n",
              " [104, 106],\n",
              " [117, 116],\n",
              " [120, 121],\n",
              " [126, 124],\n",
              " [130, 128],\n",
              " [142, 141],\n",
              " [144, 146],\n",
              " [148, 150],\n",
              " [160, 162]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAfUe0gt6-Yc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7010601c-e19f-49b0-eca3-effb317042da"
      },
      "source": [
        "def generate_paired_samples(paired_idx_lst, table, hr_algo_version):\r\n",
        "    \"\"\"\r\n",
        "    Use the index of paired devices (output from find_pairs_row_index) to generate\r\n",
        "    a list of PairedSample instances\r\n",
        "\r\n",
        "    params:\r\n",
        "    paired_idx_lst: a list containing the row index of paired devices, \r\n",
        "                    It is the output of function find_pairs_row_index.\r\n",
        "    table: a Pandas dataframe that stores test infomation, it is the output of the\r\n",
        "           correct_label() \r\n",
        "\r\n",
        "    outputs:\r\n",
        "    A list of PairedSample instances\r\n",
        "    \"\"\"\r\n",
        "    paired_sample_lst = []\r\n",
        "    for polar_idx, floyer_idx in paired_idx_lst:\r\n",
        "        polar_hash_id = table['df id'].loc[polar_idx]\r\n",
        "        floyer_hash_id = table['df id'].loc[floyer_idx]\r\n",
        "        paired_sample_lst.append(PairedSample(polar_hash_id, floyer_hash_id, hr_algo_version))\r\n",
        "    return paired_sample_lst\r\n",
        "\r\n",
        "paired_sample_lst = generate_paired_samples(paired_idx_lst, table, 'v0')\r\n",
        "# save the paried sample list to save time on next run\r\n",
        "with open(\"C:/Users/57lzhang.US04WW4008/PycharmProjects/cosinuss/paired_sample.pkl\", \"wb\") as fp:\r\n",
        "    pickle.dump(paired_sample_lst, fp)"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-05 11:24:32 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.C4CDEZ completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:24:50 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.38CD8K completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:24:53 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.XCMFW1 completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:25:11 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.G2HHR3 completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:25:14 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.2UJU2G completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:25:32 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.009DDE completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:25:34 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.58DZ5Z completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:25:51 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.V5BXYZ completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:25:54 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.60SWCR completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:26:10 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.C0KF6Y completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:26:14 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.4NGWZ3 completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:26:31 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.DYPFM1 completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:26:34 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.QNW02T completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:26:50 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.JYKU22 completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:26:53 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.08ZUGQ completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:27:10 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.N74KKE completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:27:13 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.GND7BQ completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:27:31 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.2E4QXX completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:27:33 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.ZBY97Y completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n",
            "2021-03-05 11:27:51 -  INFO -     api_db_sync: 429 - Data file 1C2RATHBVH.8HL047 completely downloaded + database_entries: Scope, Config, Projects (4), Receivers (3), Persons (27), Devices (4)User (6), \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFT24cesFnOr"
      },
      "source": [
        "with open(\"C:/Users/57lzhang.US04WW4008/PycharmProjects/cosinuss/paired_sample.pkl\", \"rb\") as fp:\r\n",
        "    paired_sample_lst = pickle.load(fp)"
      ],
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Cuc93RnZfeZ"
      },
      "source": [
        "##Continue here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr1ZdxwuVgZm"
      },
      "source": [
        "##process the df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf90w8z9mrQ_"
      },
      "source": [
        "class PairedSample:\r\n",
        "    \r\n",
        "    def __init__(self, polar_hash_id, floyer_hash_id, hr_algo_version):\r\n",
        "        self.polar_hash_id = polar_hash_id\r\n",
        "        self.floyer_hash_id = floyer_hash_id\r\n",
        "        self.header_polar = api.pull_df(polar_hash_id)\r\n",
        "        self.header_floyer = api.pull_df(floyer_hash_id)\r\n",
        "        self.person_id = self.header_floyer.person.hash_id\r\n",
        "        self.hr_algo_version = hr_algo_version\r\n",
        "        self.df = pd.DataFrame()\r\n",
        "    \r\n",
        "    def process(self):\r\n",
        "        \"\"\"\r\n",
        "        Generate a pandas table for data analysis\r\n",
        "        \"\"\"\r\n",
        "        # read polar data\r\n",
        "        polar = DataFile.objects(_hash_id=self.polar_hash_id).first()\r\n",
        "        polar_hr_x = polar.c.heart_rate.x\r\n",
        "        polar_hr_y = polar.c.heart_rate.y\r\n",
        "\r\n",
        "        # process floyer data with heart rate algorithm\r\n",
        "        floyer = api.one3_hr_algo(self.hr_algo_version, self.floyer_hash_id)\r\n",
        "        floyer_hr_x = np.asarray(floyer['heart_rate_t'])\r\n",
        "        floyer_hr_y = floyer['heart_rate']\r\n",
        "        floyer_quality = floyer['quality']\r\n",
        "\r\n",
        "        offset = (self.header_floyer.date_time_start - self.header_polar.date_time_start).total_seconds()\r\n",
        "\r\n",
        "        # get the activity label\r\n",
        "        activity_label = ['Unknown'] * len(floyer_hr_x)\r\n",
        "        for i in range(len(self.header_floyer.chunks_labelled)):\r\n",
        "            i_th_activity_start = self.header_floyer.chunks_labelled[i].time_offset\r\n",
        "            i_th_activity_duration = self.header_floyer.chunks_labelled[i].duration\r\n",
        "            i_th_activity_end = i_th_activity_start + i_th_activity_duration\r\n",
        "            \r\n",
        "            activity_label[round(i_th_activity_start):round(i_th_activity_end)] = \\\r\n",
        "            [self.header_floyer.chunk_labels[i]] * (round(i_th_activity_end) - round(i_th_activity_start))\r\n",
        "        \r\n",
        "        # if floyer starts later\r\n",
        "        if offset > 0:\r\n",
        "            polar_hr = polar_hr_y[int(offset):]\r\n",
        "            duration = min(len(polar_hr), len(floyer_hr_y))\r\n",
        "            \r\n",
        "            final_polar_hr = polar_hr[:duration]\r\n",
        "            final_floyer_hr = floyer_hr_y[:duration]\r\n",
        "            final_floyer_quality = floyer_quality[:duration]\r\n",
        "            final_floyer_activity = activity_label[:duration]\r\n",
        "\r\n",
        "        # if polar starts later\r\n",
        "        else:\r\n",
        "            floyer_hr = floyer_hr_y[-int(offset):]\r\n",
        "            floyer_qa = floyer_quality[-int(offset):]\r\n",
        "            floyer_activity = activity_label[-int(offset):]\r\n",
        "            duration = min(len(floyer_hr), len(polar_hr_y))\r\n",
        "\r\n",
        "            final_polar_hr = polar_hr_y[:duration]\r\n",
        "            final_floyer_hr = floyer_hr[:duration]\r\n",
        "            final_floyer_quality = floyer_qa[:duration]\r\n",
        "            final_floyer_activity = floyer_activity[:duration]\r\n",
        "\r\n",
        "        # add person id\r\n",
        "        final_person_id = [self.person_id] * len(final_floyer_hr)\r\n",
        "\r\n",
        "        dic = {'floyer_hr': final_floyer_hr,\r\n",
        "               'polar_hr': final_polar_hr,\r\n",
        "               'quality': final_floyer_quality,\r\n",
        "               'activity': final_floyer_activity,\r\n",
        "               'person': final_person_id \r\n",
        "               }\r\n",
        "            \r\n",
        "        self.df = pd.DataFrame(data=dic, index=None)\r\n",
        "        \r\n",
        "        return self.df"
      ],
      "execution_count": 373,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "lTG5tXY-mTpM",
        "outputId": "f1b9f3b8-c87f-4fff-d2c1-a2d09648a879"
      },
      "source": [
        "st_table"
      ],
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      floyer_hr  polar_hr  quality activity     person\n",
              "0            46        67    24442  Unknown  M9KH.ME9A\n",
              "1            45        67    25082  Unknown  M9KH.ME9A\n",
              "2            46        67    24734  Unknown  M9KH.ME9A\n",
              "3             0        68        0  Unknown  M9KH.ME9A\n",
              "4            34        68        0  Unknown  M9KH.ME9A\n",
              "...         ...       ...      ...      ...        ...\n",
              "2038        142       160        0  Unknown  M9KH.ME9A\n",
              "2039        142       159       29  Unknown  M9KH.ME9A\n",
              "2040        141       158        0  Unknown  M9KH.ME9A\n",
              "2041        139       157       47  Unknown  M9KH.ME9A\n",
              "2042        135       156       55  Unknown  M9KH.ME9A\n",
              "\n",
              "[2043 rows x 5 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>floyer_hr</th>\n",
              "      <th>polar_hr</th>\n",
              "      <th>quality</th>\n",
              "      <th>activity</th>\n",
              "      <th>person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>67</td>\n",
              "      <td>24442</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>M9KH.ME9A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>67</td>\n",
              "      <td>25082</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>M9KH.ME9A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>46</td>\n",
              "      <td>67</td>\n",
              "      <td>24734</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>M9KH.ME9A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>M9KH.ME9A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>34</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>M9KH.ME9A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2038</td>\n",
              "      <td>142</td>\n",
              "      <td>160</td>\n",
              "      <td>0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>M9KH.ME9A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2039</td>\n",
              "      <td>142</td>\n",
              "      <td>159</td>\n",
              "      <td>29</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>M9KH.ME9A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2040</td>\n",
              "      <td>141</td>\n",
              "      <td>158</td>\n",
              "      <td>0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>M9KH.ME9A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2041</td>\n",
              "      <td>139</td>\n",
              "      <td>157</td>\n",
              "      <td>47</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>M9KH.ME9A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2042</td>\n",
              "      <td>135</td>\n",
              "      <td>156</td>\n",
              "      <td>55</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>M9KH.ME9A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2043 rows Ã— 5 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 374
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00ZryvvXGcdw"
      },
      "source": [
        "def generate_stats_table(paired_sample_lst):\r\n",
        "    stats_table = pd.DataFrame(index=None)\r\n",
        "    for paired_sample in paired_sample_lst:\r\n",
        "        stats_table = stats_table.append(paired_sample.process())\r\n",
        "    return StatTable(stats_table)"
      ],
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNdCjpvge50E"
      },
      "source": [
        "stats_table = generate_stats_table(paired_sample_lst)"
      ],
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a-gY1i9GEKN"
      },
      "source": [
        "class StatTable:\r\n",
        "    \r\n",
        "    def __init__(self, df):\r\n",
        "        self.df = df\r\n",
        "\r\n",
        "    def mape(self, activity, qa_level):\r\n",
        "        \"\"\"\r\n",
        "        activity (str): the activity label\r\n",
        "        qa_level (int): the minimum requirement of signal quality for the MAPE \r\n",
        "                        calculation \r\n",
        "        \"\"\"\r\n",
        "        activity_df = self.df[self.df['activity'] == activity].reset_index()\r\n",
        "        sum = 0\r\n",
        "        count = 0\r\n",
        "        for i in range(len(activity_df)):\r\n",
        "            if activity_df['quality'][i] < 35 or activity_df['quality'][i] > 100:\r\n",
        "                continue\r\n",
        "            sum += abs(activity_df['floyer_hr'][i] - activity_df['polar_hr'][i]) / activity_df['polar_hr'][i] * 100\r\n",
        "            count += 1 \r\n",
        "        mape = round(sum / count, 2)\r\n",
        "\r\n",
        "        return mape\r\n",
        "\r\n",
        "    def da(self, activity, qa_level):\r\n",
        "        missed_cnt = 0\r\n",
        "        activity_df = self.df[self.df['activity'] == activity].reset_index()\r\n",
        "\r\n",
        "        for i in range(len(self.df)):\r\n",
        "            if self.df['quality'][i] < 35 or self.df['quality'][i] > 100:\r\n",
        "                missed_cnt += 1\r\n",
        "        da = round(missed_cnt / len(self.df), 2) * 100\r\n",
        "        return da\r\n",
        "\r\n",
        "    def icc(self):\r\n",
        "\r\n",
        "        pass\r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "    def line_plot(self):\r\n",
        "        pass \r\n",
        "        \r\n",
        "\r\n",
        "    def ba_plot(self):\r\n",
        "        pass"
      ],
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0S5QmCvD-NQ",
        "outputId": "fbcc6c94-7f68-4c00-e9a6-281f5f0a1d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "def plot_mape(stats_table, quality_level):\r\n",
        "    overall_mape = []\r\n",
        "    for i in np.unique(stats_table.df['activity']):\r\n",
        "        overall_mape.append(stats_table.mape(i, quality_level))\r\n",
        "        "
      ],
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-410-e5a569c56b18>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYIzUEW1EM4k",
        "outputId": "cc3e247f-9799-40aa-bdff-2d5b6fe07341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.unique(stats_table.df['activity'])"
      ],
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Chewing (chewing gum)', 'Running 6km/h', 'Running 8km/h',\n",
              "       'Sitting', 'Sitting - Standing - Sitting', 'Talking (read aloud)',\n",
              "       'Unknown', 'Walking 2km/h', 'Walking 4km/h'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 411
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmuoE0X8EQF9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}